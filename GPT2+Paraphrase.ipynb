{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43cd0f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\sauar\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - transformers\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    huggingface_hub-0.11.1     |     pyhd8ed1ab_0         127 KB  conda-forge\n",
      "    tokenizers-0.11.4          |   py39he5181cf_1         2.4 MB\n",
      "    transformers-4.24.0        |   py39haa95532_0         4.7 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         7.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  huggingface_hub    conda-forge/noarch::huggingface_hub-0.11.1-pyhd8ed1ab_0 \n",
      "  tokenizers         pkgs/main/win-64::tokenizers-0.11.4-py39he5181cf_1 \n",
      "  transformers       pkgs/main/win-64::transformers-4.24.0-py39haa95532_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "transformers-4.24.0  | 4.7 MB    |            |   0% \n",
      "\n",
      "tokenizers-0.11.4    | 2.4 MB    |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "huggingface_hub-0.11 | 127 KB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "huggingface_hub-0.11 | 127 KB    | #2         |  13% \u001b[A\u001b[A\n",
      "\n",
      "tokenizers-0.11.4    | 2.4 MB    |            |   1% \u001b[A\n",
      "transformers-4.24.0  | 4.7 MB    |            |   0% \n",
      "\n",
      "tokenizers-0.11.4    | 2.4 MB    | 9          |  10% \u001b[A\n",
      "\n",
      "\n",
      "huggingface_hub-0.11 | 127 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "huggingface_hub-0.11 | 127 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "transformers-4.24.0  | 4.7 MB    | 4          |   5% \n",
      "\n",
      "tokenizers-0.11.4    | 2.4 MB    | ###4       |  35% \u001b[A\n",
      "transformers-4.24.0  | 4.7 MB    | #9         |  20% \n",
      "transformers-4.24.0  | 4.7 MB    | ###        |  30% \n",
      "transformers-4.24.0  | 4.7 MB    | ####1      |  42% \n",
      "transformers-4.24.0  | 4.7 MB    | #####1     |  51% \n",
      "\n",
      "tokenizers-0.11.4    | 2.4 MB    | #####3     |  53% \u001b[A\n",
      "transformers-4.24.0  | 4.7 MB    | ######1    |  62% \n",
      "\n",
      "tokenizers-0.11.4    | 2.4 MB    | ######8    |  69% \u001b[A\n",
      "\n",
      "tokenizers-0.11.4    | 2.4 MB    | #########4 |  94% \u001b[A\n",
      "transformers-4.24.0  | 4.7 MB    | #######1   |  72% \n",
      "transformers-4.24.0  | 4.7 MB    | ########   |  81% \n",
      "\n",
      "tokenizers-0.11.4    | 2.4 MB    | ########## | 100% \u001b[A\n",
      "transformers-4.24.0  | 4.7 MB    | #########4 |  95% \n",
      "transformers-4.24.0  | 4.7 MB    | ########## | 100% \n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de9785f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a man in a black jacket carrying a black backpack']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "max_length = 16\n",
    "num_beams = 4\n",
    "gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n",
    "def predict_step(image_paths):\n",
    "    images = []\n",
    "    for image_path in image_paths:\n",
    "        i_image = Image.open(image_path)\n",
    "        if i_image.mode != \"RGB\":\n",
    "            i_image = i_image.convert(mode=\"RGB\")\n",
    "\n",
    "        images.append(i_image)\n",
    "\n",
    "    pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n",
    "    pixel_values = pixel_values.to(device)\n",
    "\n",
    "    output_ids = model.generate(pixel_values, **gen_kwargs)\n",
    "\n",
    "    preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    return preds\n",
    "\n",
    "\n",
    "predict_step(['gun.jpg']) # ['a woman in a hospital bed with a woman in a hospital bed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8398e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d10e0a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a dog and a cat playing in the water']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predict_step(['dogwater.png']) # ['a woman in a hospital bed with a woman in a hospital bed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64fd1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87d7b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ['a black and white photo man with gun', 'a person is with a gun', 'a black and white photo of a gun', 'a women riding a dirt bike on gun', 'soldier with a gun']\n",
    "h = 'a man in a suit holding a cell phone'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f59197c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2 generated caption BLEU Score 0.7590721152765896\n"
     ]
    }
   ],
   "source": [
    "print('GPT2 generated caption BLEU Score',nltk.translate.bleu_score.sentence_bleu(s,h,weights = (0.5,0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1cf2728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model generated caption BLEU Score 0.97182531580755\n"
     ]
    }
   ],
   "source": [
    "k = 'a man holding a gun' \n",
    "print('Our model generated caption BLEU Score',nltk.translate.bleu_score.sentence_bleu( s,k,weights = (0.5,0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a218cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2 generated caption BLEU Score 0.9710083124552245\n",
      "Our model generated caption BLEU Score 0.8453428098440103\n"
     ]
    }
   ],
   "source": [
    "# d = 'a black and brown dog playing in the water at a beach'\n",
    "d = ['a black and brown dog playing in the water at a beach', 'a black dog and a dog that is brown and white stand in the water', 'the large black dog and a small red and white dog are standing in the water', 'two dogs are sniffing each other while standing in a body of water', 'two dogs in the water']\n",
    "o = 'a black and white dog is running through the water'\n",
    "g = 'a dog and a cat playing in the water'\n",
    "# d = d.split(' ')\n",
    "# o = o.split(' ')\n",
    "# g = g.split(' ')\n",
    "print('GPT2 generated caption BLEU Score',nltk.translate.bleu_score.sentence_bleu(d, g,weights = (0.5,0.5)))\n",
    "print('Our model generated caption BLEU Score',nltk.translate.bleu_score.sentence_bleu(d, o,weights = (0.5,0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ccd54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d867613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5b9ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time() #a man standing next to another man holding a cell phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d0d2c55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.45050048828125"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01efb80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124.17500813802083"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(end-start)*1000/60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f407d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sauar\\anaconda3\\lib\\site-packages\\torchaudio\\backend\\utils.py:62: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a94f1fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\sauar/.cache\\huggingface\\hub\\models--tuner007--pegasus_paraphrase\\snapshots\\0159e2949ca73657a2f1329898f51b7bb53b9ab2\\config.json\n",
      "Model config PegasusConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 60,\n",
      "  \"max_position_embeddings\": 60,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\sauar/.cache\\huggingface\\hub\\models--tuner007--pegasus_paraphrase\\snapshots\\0159e2949ca73657a2f1329898f51b7bb53b9ab2\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n",
      "\n",
      "All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at tuner007/pegasus_paraphrase.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n",
      "loading file spiece.model from cache at C:\\Users\\sauar/.cache\\huggingface\\hub\\models--tuner007--pegasus_paraphrase\\snapshots\\0159e2949ca73657a2f1329898f51b7bb53b9ab2\\spiece.model\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\sauar/.cache\\huggingface\\hub\\models--tuner007--pegasus_paraphrase\\snapshots\\0159e2949ca73657a2f1329898f51b7bb53b9ab2\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\sauar/.cache\\huggingface\\hub\\models--tuner007--pegasus_paraphrase\\snapshots\\0159e2949ca73657a2f1329898f51b7bb53b9ab2\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\sauar/.cache\\huggingface\\hub\\models--tuner007--pegasus_paraphrase\\snapshots\\0159e2949ca73657a2f1329898f51b7bb53b9ab2\\config.json\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"tuner007/pegasus_paraphrase\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 60,\n",
      "  \"max_position_embeddings\": 60,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\sauar/.cache\\huggingface\\hub\\models--tuner007--pegasus_paraphrase\\snapshots\\0159e2949ca73657a2f1329898f51b7bb53b9ab2\\config.json\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"tuner007/pegasus_paraphrase\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 60,\n",
      "  \"max_position_embeddings\": 60,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = PegasusForConditionalGeneration.from_pretrained(\"tuner007/pegasus_paraphrase\")\n",
    "tokenizer = PegasusTokenizerFast.from_pretrained(\"tuner007/pegasus_paraphrase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36d099c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paraphrased_sentences(model, tokenizer, sentence, num_return_sequences=5, num_beams=5):\n",
    "  # tokenize the text to be form of a list of token IDs\n",
    "  inputs = tokenizer([sentence], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "  # generate the paraphrased sentences\n",
    "  outputs = model.generate(\n",
    "    **inputs,\n",
    "    num_beams=num_beams,\n",
    "    num_return_sequences=num_return_sequences,\n",
    "  )\n",
    "  # decode the generated sentences using the tokenizer to get them back to text\n",
    "  return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "834281ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sauar\\anaconda3\\lib\\site-packages\\transformers\\generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 60 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Learning involves the acquisition of new understanding, knowledge, behaviors, skills, values, attitudes, and preferences.',\n",
       " 'Learning is the acquisition of new understanding, knowledge, behaviors, skills, values, attitudes, and preferences.',\n",
       " 'The process of learning is the acquisition of new understanding, knowledge, behaviors, skills, values, attitudes, and preferences.',\n",
       " 'Gaining new understanding, knowledge, behaviors, skills, values, attitudes, and preferences is the process of learning.',\n",
       " 'New understanding, knowledge, behaviors, skills, values, attitudes, and preferences are acquired through learning.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Learning is the process of acquiring new understanding, knowledge, behaviors, skills, values, attitudes, and preferences.\"\n",
    "get_paraphrased_sentences(model, tokenizer, sentence, num_beams=10, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0158ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d4d4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "df  =pd.read_excel('Captions.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d29862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49c255af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = df['Caption 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "263b4c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = lis.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59cd3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = lis.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e30fa21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sauar\\anaconda3\\lib\\site-packages\\transformers\\generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 60 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cap1 = []\n",
    "cap2 = []\n",
    "cap3= []\n",
    "cap4 = []\n",
    "cap5 = []\n",
    "for i in lis:\n",
    "    n = get_paraphrased_sentences(model, tokenizer, i, num_beams=10, num_return_sequences=5)\n",
    "    cap1.append(n[0])\n",
    "    cap2.append(n[1])\n",
    "    cap3.append(n[2])\n",
    "    cap4.append(n[3])\n",
    "    cap5.append(n[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b8f6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f013b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d111bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A group of men are attacking each other.',\n",
       " 'A masked man is walking.',\n",
       " 'A man is fighting another man.',\n",
       " 'A group of men are attacking each other.',\n",
       " 'A man is harrasssing a woman.',\n",
       " 'A man is pointing a gun.',\n",
       " 'A man is near a car.',\n",
       " 'A man is harrasssing a woman.',\n",
       " 'A man is fighting another man.',\n",
       " 'A man is wearing a hoodie.',\n",
       " 'A group of men are attacking each other.',\n",
       " 'A man wearing a black shirt is attacking another man.',\n",
       " 'A group of men are attacking each other.',\n",
       " 'A group of men are attacking each other.',\n",
       " 'A masked man is holding a gun.',\n",
       " 'A man is abducting a boy.',\n",
       " 'A masked man is abducting a girl.',\n",
       " 'A man is abducting a baby.',\n",
       " 'A masked man is abducting a woman.',\n",
       " 'A man with a baseball bat is wearing a black hoodie.',\n",
       " 'A man with a baseball bat is wearing a black hoodie.',\n",
       " 'A man with a baseball bat is wearing a black hoodie.',\n",
       " 'A man with a baseball bat is wearing a white shirt.',\n",
       " 'A masked man is holding a baseball bat.',\n",
       " 'A man with a baseball bat is wearing a black hoodie.',\n",
       " 'A man with a baseball bat is wearing a black hoodie.',\n",
       " 'A man with a baseball bat is wearing a white shirt.',\n",
       " 'A man with a baseball bat is wearing a black hoodie.',\n",
       " 'A man with a baseball bat is wearing a black hoodie.',\n",
       " 'A man with a baseball bat is wearing a black hoodie.',\n",
       " 'A man with a baseball bat is wearing a black hoodie.',\n",
       " 'Two men are wearing black hoodies with baseball bats.',\n",
       " 'A man with a baseball bat is wearing a white shirt.',\n",
       " 'A masked man is holding a baseball bat.',\n",
       " 'A man with a baseball bat is wearing a black hoodie.',\n",
       " 'A man with a baseball bat is wearing a black hoodie.',\n",
       " 'A masked man is holding a baseball bat.',\n",
       " 'A man with a baseball bat is wearing a white shirt.',\n",
       " 'A masked man is in a house.',\n",
       " 'A masked man is breaking into a building.',\n",
       " 'A masked man is in a house.',\n",
       " 'Two masked men are in a house.',\n",
       " 'A man wearing a hoodie is breaking into a building.',\n",
       " 'A masked man is holding a gun.',\n",
       " 'A man wearing a hoodie is in a store.',\n",
       " 'A masked man is stealing.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac331854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
